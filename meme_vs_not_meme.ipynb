{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8633c33",
   "metadata": {},
   "source": [
    "# Meme vs. Non-Meme Binary Classification Model\n",
    "\n",
    "## Project Overview\n",
    "This notebook implements a deep learning binary classification model to distinguish between **memes** and **non-memes** using a Mini-ResNet architecture with advanced dataset handling capabilities.\n",
    "\n",
    "## Objective\n",
    "Build a high-performance binary classifier that can accurately identify whether an image is:\n",
    "- **Class 1 (Meme)**: Image contains meme content\n",
    "- **Class 0 (Non-Meme)**: Image does not contain meme content\n",
    "\n",
    "## Model Architecture\n",
    "- **Architecture**: Mini-ResNet with skip connections\n",
    "- **Key Features**:\n",
    "  - Residual connections for improved gradient flow\n",
    "  - Global Average Pooling for computational efficiency\n",
    "  - Sigmoid activation for binary classification\n",
    "  - Data augmentation to prevent overfitting\n",
    "\n",
    "## Advanced Dataset Features\n",
    "- **Nested Folder Support**: Automatically handles images in nested subfolders\n",
    "- **Image Validation**: Validates each image file before training\n",
    "- **Auto-Filtering**: Filters out corrupted or invalid images automatically\n",
    "- **Automatic Balancing**: Ensures equal samples per class to prevent bias\n",
    "- **Smart Sampling**: Randomly selects from larger class to match smaller class\n",
    "- **Configurable Max Limit**: Set maximum images per class with intelligent fallback\n",
    "- **Multiple Formats**: Supports .jpg, .jpeg, .png, .bmp, .gif images\n",
    "\n",
    "## Dataset\n",
    "- **Source**: `meme_vs_not_meme_dataset/` directory\n",
    "- **Split**: 70% Training / 15% Validation / 15% Testing\n",
    "- **Image Size**: 224×224 pixels\n",
    "- **Classes**: `meme/` and `not_meme/` folders (nested subfolders supported)\n",
    "- **Validation**: All images validated before training (corrupted files filtered)\n",
    "- **Balancing**: Automatic class balancing to prevent model bias\n",
    "- **Max Limit**: Optional `MAX_IMAGES_PER_CLASS` configuration (default: 10000)\n",
    "\n",
    "## Training Configuration\n",
    "- **Optimizer**: ADAM (learning rate: 0.0001)\n",
    "- **Batch Size**: 2\n",
    "- **Epochs**: 15\n",
    "- **Callbacks**: Early Stopping, Model Checkpoint\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3bcff8",
   "metadata": {},
   "source": [
    "## 1. Library Imports\n",
    "Import all necessary libraries for building, training, and evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbcaed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] TensorFlow version: 2.19.0\n",
      "[INFO] GPU available: []\n",
      "[INFO] Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import pathlib\n",
    "import shutil\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "print(f\"[INFO] TensorFlow version: {tf.__version__}\")\n",
    "print(f\"[INFO] GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"[INFO] Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557635d1",
   "metadata": {},
   "source": [
    "## 2. Dataset Configuration\n",
    "Configure the dataset directory and verify it exists with proper structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40bf8447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset directory configured successfully\n",
      "       >> Dataset directory: ./meme_vs_not_meme_dataset\n",
      "       >> Model save directory: ./models\n",
      "       >> Classes found: ['meme', 'not_meme']\n"
     ]
    }
   ],
   "source": [
    "# Dataset directory configuration\n",
    "DATASET_DIR = \"./meme_vs_not_meme_dataset\"\n",
    "MODEL_SAVE_DIR = \"./models\"\n",
    "\n",
    "# Verify dataset directory exists\n",
    "if not os.path.exists(DATASET_DIR):\n",
    "    raise ValueError(f\"[ERROR] Dataset directory not found: {DATASET_DIR}\")\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Get class names\n",
    "data_dir = pathlib.Path(DATASET_DIR)\n",
    "class_names = [item.name for item in data_dir.iterdir() if item.is_dir()]\n",
    "class_names.sort()\n",
    "\n",
    "print(f\"[INFO] Dataset directory configured successfully\")\n",
    "print(f\"       >> Dataset directory: {DATASET_DIR}\")\n",
    "print(f\"       >> Model save directory: {MODEL_SAVE_DIR}\")\n",
    "print(f\"       >> Classes found: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aac29b",
   "metadata": {},
   "source": [
    "## 2.1. Dataset Preparation - Handle Nested Folders & Balancing\n",
    "Scan for images in nested subfolders and balance the dataset to prevent bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "126e8862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Scanning for images in nested folders...\n",
      "================================================================================\n",
      "       >> Scanning directory: meme\n",
      "       >> Found 11817 potential image files\n",
      "       >> Validating images (this may take a moment)...\n",
      "       >> Found 11817 potential image files\n",
      "       >> Validating images (this may take a moment)...\n",
      "       >> Filtered out 37 invalid/corrupted images\n",
      "       >> Valid images: 11780\n",
      "       >> Scanning directory: not_meme\n",
      "       >> Filtered out 37 invalid/corrupted images\n",
      "       >> Valid images: 11780\n",
      "       >> Scanning directory: not_meme\n",
      "       >> Found 61214 potential image files\n",
      "       >> Validating images (this may take a moment)...\n",
      "       >> Found 61214 potential image files\n",
      "       >> Validating images (this may take a moment)...\n",
      "       >> Valid images: 61214\n",
      "\n",
      "[INFO] Valid images found:\n",
      "       >> Meme images: 11780\n",
      "       >> Not-Meme images: 61214\n",
      "\n",
      "[INFO] Maximum images per class limit: 10000\n",
      "       >> Meme folder has 11780 images, limiting to 10000\n",
      "       >> Not-Meme folder has 61214 images, limiting to 10000\n",
      "\n",
      "[INFO] Dataset is already balanced!\n",
      "\n",
      "[INFO] Final balanced dataset:\n",
      "       >> Meme images: 10000\n",
      "       >> Not-Meme images: 10000\n",
      "       >> Total images: 20000\n",
      "================================================================================\n",
      "       >> Valid images: 61214\n",
      "\n",
      "[INFO] Valid images found:\n",
      "       >> Meme images: 11780\n",
      "       >> Not-Meme images: 61214\n",
      "\n",
      "[INFO] Maximum images per class limit: 10000\n",
      "       >> Meme folder has 11780 images, limiting to 10000\n",
      "       >> Not-Meme folder has 61214 images, limiting to 10000\n",
      "\n",
      "[INFO] Dataset is already balanced!\n",
      "\n",
      "[INFO] Final balanced dataset:\n",
      "       >> Meme images: 10000\n",
      "       >> Not-Meme images: 10000\n",
      "       >> Total images: 20000\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Maximum images per class configuration\n",
    "# Set to None for no limit, or specify a number (e.g., 10000)\n",
    "MAX_IMAGES_PER_CLASS = 10000\n",
    "\n",
    "# Function to validate if a file is a valid image\n",
    "def is_valid_image(file_path):\n",
    "    \"\"\"\n",
    "    Check if a file is a valid image by attempting to open it with TensorFlow.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the image file\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if valid image, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to read and decode the image\n",
    "        img_bytes = tf.io.read_file(file_path)\n",
    "        img = tf.io.decode_image(img_bytes, channels=3, expand_animations=False)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Function to collect all images from nested subfolders\n",
    "def collect_images_from_nested_folders(base_dir, image_extensions=['.jpg', '.jpeg', '.png', '.bmp', '.gif']):\n",
    "    \"\"\"\n",
    "    Recursively collect all valid image file paths from a directory and its subdirectories.\n",
    "    Validates each image to ensure it can be loaded by TensorFlow.\n",
    "    \n",
    "    Args:\n",
    "        base_dir (str): Base directory to search\n",
    "        image_extensions (list): List of valid image file extensions\n",
    "    \n",
    "    Returns:\n",
    "        list: List of all valid image file paths\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    invalid_count = 0\n",
    "    \n",
    "    print(f\"       >> Scanning directory: {os.path.basename(base_dir)}\")\n",
    "    \n",
    "    # Collect potential image files\n",
    "    for ext in image_extensions:\n",
    "        image_paths.extend(glob(os.path.join(base_dir, '**', f'*{ext}'), recursive=True))\n",
    "        image_paths.extend(glob(os.path.join(base_dir, '**', f'*{ext.upper()}'), recursive=True))\n",
    "    \n",
    "    # Remove duplicates\n",
    "    image_paths = list(set(image_paths))\n",
    "    \n",
    "    print(f\"       >> Found {len(image_paths)} potential image files\")\n",
    "    print(f\"       >> Validating images (this may take a moment)...\")\n",
    "    \n",
    "    # Validate images\n",
    "    valid_images = []\n",
    "    for img_path in image_paths:\n",
    "        if is_valid_image(img_path):\n",
    "            valid_images.append(img_path)\n",
    "        else:\n",
    "            invalid_count += 1\n",
    "    \n",
    "    if invalid_count > 0:\n",
    "        print(f\"       >> Filtered out {invalid_count} invalid/corrupted images\")\n",
    "    \n",
    "    print(f\"       >> Valid images: {len(valid_images)}\")\n",
    "    \n",
    "    return valid_images\n",
    "\n",
    "# Collect images from both meme and not_meme folders (including nested subfolders)\n",
    "meme_dir = os.path.join(DATASET_DIR, \"meme\")\n",
    "not_meme_dir = os.path.join(DATASET_DIR, \"not_meme\")\n",
    "\n",
    "print(\"[INFO] Scanning for images in nested folders...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Collect all valid image paths\n",
    "meme_images = collect_images_from_nested_folders(meme_dir)\n",
    "not_meme_images = collect_images_from_nested_folders(not_meme_dir)\n",
    "\n",
    "print(f\"\\n[INFO] Valid images found:\")\n",
    "print(f\"       >> Meme images: {len(meme_images)}\")\n",
    "print(f\"       >> Not-Meme images: {len(not_meme_images)}\")\n",
    "\n",
    "# Check if dataset is empty\n",
    "if len(meme_images) == 0 or len(not_meme_images) == 0:\n",
    "    raise ValueError(\"[ERROR] One or both class folders are empty or contain no valid images. Please add valid images to train the model.\")\n",
    "\n",
    "# Apply maximum images per class limit if configured\n",
    "if MAX_IMAGES_PER_CLASS is not None:\n",
    "    print(f\"\\n[INFO] Maximum images per class limit: {MAX_IMAGES_PER_CLASS}\")\n",
    "    \n",
    "    # Apply limit to meme images\n",
    "    if len(meme_images) > MAX_IMAGES_PER_CLASS:\n",
    "        print(f\"       >> Meme folder has {len(meme_images)} images, limiting to {MAX_IMAGES_PER_CLASS}\")\n",
    "        random.seed(42)\n",
    "        meme_images = random.sample(meme_images, MAX_IMAGES_PER_CLASS)\n",
    "    else:\n",
    "        print(f\"       >> Meme folder has {len(meme_images)} images (below limit)\")\n",
    "    \n",
    "    # Apply limit to not_meme images\n",
    "    if len(not_meme_images) > MAX_IMAGES_PER_CLASS:\n",
    "        print(f\"       >> Not-Meme folder has {len(not_meme_images)} images, limiting to {MAX_IMAGES_PER_CLASS}\")\n",
    "        random.seed(42)\n",
    "        not_meme_images = random.sample(not_meme_images, MAX_IMAGES_PER_CLASS)\n",
    "    else:\n",
    "        print(f\"       >> Not-Meme folder has {len(not_meme_images)} images (below limit)\")\n",
    "\n",
    "# Balance the dataset (ensure equal samples per class)\n",
    "min_images = min(len(meme_images), len(not_meme_images))\n",
    "\n",
    "if len(meme_images) != len(not_meme_images):\n",
    "    print(f\"\\n[INFO] Dataset imbalance detected!\")\n",
    "    print(f\"       >> Balancing dataset to {min_images} images per class\")\n",
    "    \n",
    "    # Randomly sample from the larger dataset\n",
    "    random.seed(42)  # For reproducibility\n",
    "    if len(meme_images) > min_images:\n",
    "        meme_images = random.sample(meme_images, min_images)\n",
    "        print(f\"       >> Randomly selected {min_images} images from meme folder\")\n",
    "    if len(not_meme_images) > min_images:\n",
    "        not_meme_images = random.sample(not_meme_images, min_images)\n",
    "        print(f\"       >> Randomly selected {min_images} images from not_meme folder\")\n",
    "else:\n",
    "    print(f\"\\n[INFO] Dataset is already balanced!\")\n",
    "\n",
    "print(f\"\\n[INFO] Final balanced dataset:\")\n",
    "print(f\"       >> Meme images: {len(meme_images)}\")\n",
    "print(f\"       >> Not-Meme images: {len(not_meme_images)}\")\n",
    "print(f\"       >> Total images: {len(meme_images) + len(not_meme_images)}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67397e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating temporary balanced dataset structure...\n",
      "       >> Copying 10000 meme images...\n",
      "       >> Copying 10000 meme images...\n",
      "       >> Copying 10000 not-meme images...\n",
      "       >> Copying 10000 not-meme images...\n",
      "[INFO] Temporary balanced dataset created at: ./temp_balanced_dataset\n",
      "       >> This temporary dataset will be used for training\n",
      "       >> Original dataset remains unchanged\n",
      "================================================================================\n",
      "[INFO] Temporary balanced dataset created at: ./temp_balanced_dataset\n",
      "       >> This temporary dataset will be used for training\n",
      "       >> Original dataset remains unchanged\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary balanced dataset directory structure\n",
    "TEMP_DATASET_DIR = \"./temp_balanced_dataset\"\n",
    "TEMP_MEME_DIR = os.path.join(TEMP_DATASET_DIR, \"meme\")\n",
    "TEMP_NOT_MEME_DIR = os.path.join(TEMP_DATASET_DIR, \"not_meme\")\n",
    "\n",
    "print(\"[INFO] Creating temporary balanced dataset structure...\")\n",
    "\n",
    "# Remove temporary directory if it exists\n",
    "if os.path.exists(TEMP_DATASET_DIR):\n",
    "    shutil.rmtree(TEMP_DATASET_DIR)\n",
    "\n",
    "# Create new temporary directories\n",
    "os.makedirs(TEMP_MEME_DIR, exist_ok=True)\n",
    "os.makedirs(TEMP_NOT_MEME_DIR, exist_ok=True)\n",
    "\n",
    "# Copy balanced images to temporary directory\n",
    "print(f\"       >> Copying {len(meme_images)} meme images...\")\n",
    "for i, img_path in enumerate(meme_images):\n",
    "    ext = os.path.splitext(img_path)[1]\n",
    "    dest_path = os.path.join(TEMP_MEME_DIR, f\"meme_{i:05d}{ext}\")\n",
    "    shutil.copy2(img_path, dest_path)\n",
    "\n",
    "print(f\"       >> Copying {len(not_meme_images)} not-meme images...\")\n",
    "for i, img_path in enumerate(not_meme_images):\n",
    "    ext = os.path.splitext(img_path)[1]\n",
    "    dest_path = os.path.join(TEMP_NOT_MEME_DIR, f\"not_meme_{i:05d}{ext}\")\n",
    "    shutil.copy2(img_path, dest_path)\n",
    "\n",
    "print(f\"[INFO] Temporary balanced dataset created at: {TEMP_DATASET_DIR}\")\n",
    "print(f\"       >> This temporary dataset will be used for training\")\n",
    "print(f\"       >> Original dataset remains unchanged\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b924a9d",
   "metadata": {},
   "source": [
    "## 3. Hyperparameters Configuration\n",
    "Set image dimensions, batch size, learning rate, and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8174857b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Hyperparameters configured:\n",
      "       >> Image size: (224, 224)\n",
      "       >> Batch size: 2\n",
      "       >> Epochs: 15\n",
      "       >> Learning rate: 0.0001\n",
      "       >> Dataset split: 70% Train / 15% Val / 15% Test\n",
      "       >> Max images per class: 10000\n"
     ]
    }
   ],
   "source": [
    "# Image parameters and hyperparameters\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Dataset split ratios (70% train, 15% validation, 15% test)\n",
    "TRAIN_RATIO = 0.70\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "print(f\"[INFO] Hyperparameters configured:\")\n",
    "print(f\"       >> Image size: {IMG_SIZE}\")\n",
    "print(f\"       >> Batch size: {BATCH_SIZE}\")\n",
    "print(f\"       >> Epochs: {EPOCHS}\")\n",
    "print(f\"       >> Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"       >> Dataset split: {TRAIN_RATIO:.0%} Train / {VAL_RATIO:.0%} Val / {TEST_RATIO:.0%} Test\")\n",
    "print(f\"       >> Max images per class: {MAX_IMAGES_PER_CLASS if MAX_IMAGES_PER_CLASS else 'No limit'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784cf59",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing & Augmentation\n",
    "Load the dataset with proper train-validation-test split and apply data augmentation to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa34e73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading balanced dataset...\n",
      "================================================================================\n",
      "Found 20000 files belonging to 2 classes.\n",
      "Found 20000 files belonging to 2 classes.\n",
      "[INFO] Dataset loaded and split successfully\n",
      "       >> Total batches: 10000\n",
      "       >> Training batches: 7000 (~14000 images)\n",
      "       >> Validation batches: 1500 (~3000 images)\n",
      "       >> Test batches: 1500 (~3000 images)\n",
      "       >> Class names: ['meme', 'not_meme']\n",
      "       >> Dataset is balanced: ✓ Equal samples per class\n",
      "================================================================================\n",
      "[INFO] Dataset loaded and split successfully\n",
      "       >> Total batches: 10000\n",
      "       >> Training batches: 7000 (~14000 images)\n",
      "       >> Validation batches: 1500 (~3000 images)\n",
      "       >> Test batches: 1500 (~3000 images)\n",
      "       >> Class names: ['meme', 'not_meme']\n",
      "       >> Dataset is balanced: ✓ Equal samples per class\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load the balanced dataset\n",
    "print(\"[INFO] Loading balanced dataset...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "full_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEMP_DATASET_DIR,  # Use temporary balanced dataset\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='binary',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Get total dataset size\n",
    "total_batches = tf.data.experimental.cardinality(full_dataset).numpy()\n",
    "total_images = total_batches * BATCH_SIZE\n",
    "\n",
    "# Calculate split sizes\n",
    "train_size = int(TRAIN_RATIO * total_batches)\n",
    "val_size = int(VAL_RATIO * total_batches)\n",
    "test_size = total_batches - train_size - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_ds_raw = full_dataset.take(train_size)\n",
    "remaining = full_dataset.skip(train_size)\n",
    "val_ds = remaining.take(val_size)\n",
    "test_ds = remaining.skip(val_size)\n",
    "\n",
    "print(f\"[INFO] Dataset loaded and split successfully\")\n",
    "print(f\"       >> Total batches: {total_batches}\")\n",
    "print(f\"       >> Training batches: {train_size} (~{train_size * BATCH_SIZE} images)\")\n",
    "print(f\"       >> Validation batches: {val_size} (~{val_size * BATCH_SIZE} images)\")\n",
    "print(f\"       >> Test batches: {test_size} (~{test_size * BATCH_SIZE} images)\")\n",
    "print(f\"       >> Class names: {full_dataset.class_names}\")\n",
    "print(f\"       >> Dataset is balanced: ✓ Equal samples per class\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e29f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data augmentation and normalization applied\n",
      "       >> Augmentation: Random Rotation (±15°), Flip, Contrast, Zoom, Translation\n",
      "       >> Normalization: Pixel values scaled to [0, 1]\n",
      "       >> Training dataset: Augmented + Normalized\n",
      "       >> Validation/Test datasets: Normalized only\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation layers for training\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.0417),  # ±15 degrees (15/360 = 0.0417)\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "# Normalization layer (rescale to [0, 1])\n",
    "normalization = layers.Rescaling(1./255, name=\"normalization\")\n",
    "\n",
    "# Apply augmentation and normalization to training data\n",
    "def prepare_train(ds):\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(lambda x, y: (normalization(x), y), \n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Apply only normalization to validation and test data\n",
    "def prepare_val_test(ds):\n",
    "    ds = ds.map(lambda x, y: (normalization(x), y), \n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Prepare datasets\n",
    "train_ds = prepare_train(train_ds_raw)\n",
    "val_ds = prepare_val_test(val_ds)\n",
    "test_ds = prepare_val_test(test_ds)\n",
    "\n",
    "print(f\"[INFO] Data augmentation and normalization applied\")\n",
    "print(f\"       >> Augmentation: Random Rotation (±15°), Flip, Contrast, Zoom, Translation\")\n",
    "print(f\"       >> Normalization: Pixel values scaled to [0, 1]\")\n",
    "print(f\"       >> Training dataset: Augmented + Normalized\")\n",
    "print(f\"       >> Validation/Test datasets: Normalized only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81733e1",
   "metadata": {},
   "source": [
    "## 5. Mini-ResNet Model Architecture\n",
    "Build a Mini-ResNet model with residual (skip) connections for improved gradient flow and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfe251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Residual block function defined\n"
     ]
    }
   ],
   "source": [
    "# Residual Block with Skip Connection\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, name=None):\n",
    "    \"\"\"\n",
    "    Creates a residual block with skip connection.\n",
    "    \n",
    "    Args:\n",
    "        x: Input tensor\n",
    "        filters: Number of filters in convolutional layers\n",
    "        kernel_size: Size of convolution kernel\n",
    "        stride: Stride for convolution\n",
    "        name: Name prefix for layers\n",
    "    \n",
    "    Returns:\n",
    "        Output tensor with residual connection applied\n",
    "    \"\"\"\n",
    "    # Save input for skip connection\n",
    "    shortcut = x\n",
    "    \n",
    "    # First convolution\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', \n",
    "                     name=f\"{name}_conv1\")(x)\n",
    "    x = layers.BatchNormalization(name=f\"{name}_bn1\")(x)\n",
    "    x = layers.ReLU(name=f\"{name}_relu1\")(x)\n",
    "    \n",
    "    # Second convolution\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=1, padding='same', \n",
    "                     name=f\"{name}_conv2\")(x)\n",
    "    x = layers.BatchNormalization(name=f\"{name}_bn2\")(x)\n",
    "    \n",
    "    # Adjust shortcut dimensions if needed\n",
    "    if stride != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride, padding='same', \n",
    "                                name=f\"{name}_shortcut_conv\")(shortcut)\n",
    "        shortcut = layers.BatchNormalization(name=f\"{name}_shortcut_bn\")(shortcut)\n",
    "    \n",
    "    # Add skip connection\n",
    "    x = layers.Add(name=f\"{name}_add\")([x, shortcut])\n",
    "    x = layers.ReLU(name=f\"{name}_relu2\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "print(\"[INFO] Residual block function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cec5b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Mini-ResNet model built successfully\n",
      "       >> Total layers: 59\n",
      "       >> Total parameters: 2,867,393\n",
      "       >> Optimizer: Adam (lr=0.0001)\n",
      "       >> Loss function: Binary Crossentropy\n"
     ]
    }
   ],
   "source": [
    "# Build Mini-ResNet Model\n",
    "def build_mini_resnet(img_height, img_width, learning_rate):\n",
    "    \"\"\"\n",
    "    Build a Mini-ResNet model with skip connections for binary classification.\n",
    "    \n",
    "    Architecture:\n",
    "    - Initial Conv layer\n",
    "    - 3 Residual blocks with increasing filters (64, 128, 256)\n",
    "    - Global Average Pooling for efficiency\n",
    "    - Dense layers with dropout\n",
    "    - Sigmoid output for binary classification\n",
    "    \n",
    "    Args:\n",
    "        img_height (int): Height of input images\n",
    "        img_width (int): Width of input images\n",
    "        learning_rate (float): Learning rate for Adam optimizer\n",
    "    \n",
    "    Returns:\n",
    "        Model: Compiled Keras model\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(img_height, img_width, 3), name=\"input\")\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = layers.Conv2D(32, 7, strides=2, padding='same', name=\"initial_conv\")(inputs)\n",
    "    x = layers.BatchNormalization(name=\"initial_bn\")(x)\n",
    "    x = layers.ReLU(name=\"initial_relu\")(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding='same', name=\"initial_pool\")(x)\n",
    "    \n",
    "    # Residual blocks with increasing complexity\n",
    "    x = residual_block(x, 64, name=\"res_block1\")\n",
    "    x = residual_block(x, 64, name=\"res_block2\")\n",
    "    \n",
    "    x = residual_block(x, 128, stride=2, name=\"res_block3\")\n",
    "    x = residual_block(x, 128, name=\"res_block4\")\n",
    "    \n",
    "    x = residual_block(x, 256, stride=2, name=\"res_block5\")\n",
    "    x = residual_block(x, 256, name=\"res_block6\")\n",
    "    \n",
    "    # Global Average Pooling for computational efficiency\n",
    "    x = layers.GlobalAveragePooling2D(name=\"global_avg_pool\")(x)\n",
    "    \n",
    "    # Dense layers with dropout for regularization\n",
    "    x = layers.Dense(256, activation='relu', name=\"dense1\")(x)\n",
    "    x = layers.Dropout(0.5, name=\"dropout1\")(x)\n",
    "    x = layers.Dense(128, activation='relu', name=\"dense2\")(x)\n",
    "    x = layers.Dropout(0.3, name=\"dropout2\")(x)\n",
    "    \n",
    "    # Output layer with sigmoid for binary classification\n",
    "    outputs = layers.Dense(1, activation='sigmoid', name=\"output\")(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"Mini_ResNet\")\n",
    "    \n",
    "    # Compile model with Adam optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"[INFO] Mini-ResNet model built successfully\")\n",
    "    print(f\"       >> Total layers: {len(model.layers)}\")\n",
    "    print(f\"       >> Total parameters: {model.count_params():,}\")\n",
    "    print(f\"       >> Optimizer: Adam (lr={learning_rate})\")\n",
    "    print(f\"       >> Loss function: Binary Crossentropy\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_mini_resnet(IMG_HEIGHT, IMG_WIDTH, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "829c5761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model Architecture Summary:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Mini_ResNet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Mini_ResNet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ initial_conv        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,736</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ initial_bn          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ initial_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ initial_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ initial_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ initial_pool        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ initial_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_conv1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ initial_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_bn1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ res_block1_conv1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_relu1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block1_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_conv2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ res_block1_relu1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_shortcu… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ initial_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_bn2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ res_block1_conv2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_shortcu… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ res_block1_short… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block1_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ res_block1_short… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_relu2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_conv1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ res_block1_relu2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_bn1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ res_block2_conv1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_relu1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block2_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_conv2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ res_block2_relu1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_bn2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ res_block2_conv2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block2_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ res_block1_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_relu2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_conv1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ res_block2_relu2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_bn1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ res_block3_conv1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_relu1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block3_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_conv2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ res_block3_relu1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_shortcu… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ res_block2_relu2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_bn2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ res_block3_conv2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_shortcu… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ res_block3_short… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block3_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ res_block3_short… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_relu2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block3_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_conv1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ res_block3_relu2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_bn1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ res_block4_conv1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_relu1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block4_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_conv2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ res_block4_relu1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_bn2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ res_block4_conv2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block4_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ res_block3_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_relu2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block4_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_conv1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ res_block4_relu2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_bn1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ res_block5_conv1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_relu1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block5_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_conv2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ res_block5_relu1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_shortcu… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ res_block4_relu2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_bn2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ res_block5_conv2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_shortcu… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ res_block5_short… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block5_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ res_block5_short… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_relu2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block5_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_conv1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ res_block5_relu2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_bn1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ res_block6_conv1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_relu1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block6_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_conv2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ res_block6_relu1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_bn2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ res_block6_conv2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block6_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ res_block5_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_relu2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block6_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_avg_pool     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ res_block6_relu2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ global_avg_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ initial_conv        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │      \u001b[38;5;34m4,736\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ initial_bn          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ initial_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ initial_relu (\u001b[38;5;33mReLU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ initial_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ initial_pool        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ initial_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_conv1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ initial_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_bn1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ res_block1_conv1… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_relu1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block1_bn1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_conv2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ res_block1_relu1… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_shortcu… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │      \u001b[38;5;34m2,112\u001b[0m │ initial_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_bn2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ res_block1_conv2… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_shortcu… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ res_block1_short… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block1_bn2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m64\u001b[0m)               │            │ res_block1_short… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block1_relu2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block1_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_conv1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ res_block1_relu2… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_bn1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ res_block2_conv1… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_relu1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block2_bn1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_conv2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ res_block2_relu1… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_bn2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ res_block2_conv2… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block2_bn2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m64\u001b[0m)               │            │ res_block1_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block2_relu2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block2_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_conv1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ res_block2_relu2… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_bn1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ res_block3_conv1… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_relu1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block3_bn1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_conv2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ res_block3_relu1… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_shortcu… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ res_block2_relu2… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_bn2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ res_block3_conv2… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_shortcu… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ res_block3_short… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block3_bn2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)              │            │ res_block3_short… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block3_relu2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block3_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_conv1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ res_block3_relu2… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_bn1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ res_block4_conv1… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_relu1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block4_bn1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_conv2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ res_block4_relu1… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_bn2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ res_block4_conv2… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block4_bn2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)              │            │ res_block3_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block4_relu2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block4_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_conv1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m295,168\u001b[0m │ res_block4_relu2… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_bn1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ res_block5_conv1… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_relu1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block5_bn1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_conv2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m590,080\u001b[0m │ res_block5_relu1… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_shortcu… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m33,024\u001b[0m │ res_block4_relu2… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_bn2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ res_block5_conv2… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_shortcu… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ res_block5_short… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block5_bn2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m256\u001b[0m)              │            │ res_block5_short… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block5_relu2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block5_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_conv1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m590,080\u001b[0m │ res_block5_relu2… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_bn1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ res_block6_conv1… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_relu1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block6_bn1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_conv2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m590,080\u001b[0m │ res_block6_relu1… │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_bn2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ res_block6_conv2… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block6_bn2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │ \u001b[38;5;34m256\u001b[0m)              │            │ res_block5_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ res_block6_relu2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ res_block6_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReLU\u001b[0m)              │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_avg_pool     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ res_block6_relu2… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ global_avg_pool[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense2 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,867,393</span> (10.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,867,393\u001b[0m (10.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,862,849</span> (10.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,862,849\u001b[0m (10.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,544</span> (17.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,544\u001b[0m (17.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary\n",
    "print(\"[INFO] Model Architecture Summary:\")\n",
    "print(\"=\" * 80)\n",
    "model.summary()\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4edfb1",
   "metadata": {},
   "source": [
    "## 6. Training Configuration\n",
    "Configure callbacks for optimal training: Early Stopping and Model Checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7a850db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training callbacks configured:\n",
      "       >> Early Stopping: Patience=5, Monitor='val_loss'\n",
      "       >> Model Checkpoint: Save best model to './models\\meme_detector_model.h5'\n",
      "       >> Callbacks ready for training\n"
     ]
    }
   ],
   "source": [
    "# Configure training callbacks\n",
    "MODEL_CHECKPOINT_PATH = os.path.join(MODEL_SAVE_DIR, \"meme_detector_model.h5\")\n",
    "\n",
    "# Early Stopping: Stop training when validation loss stops improving\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Model Checkpoint: Save the best model during training\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=MODEL_CHECKPOINT_PATH,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_list = [early_stopping, model_checkpoint]\n",
    "\n",
    "print(f\"[INFO] Training callbacks configured:\")\n",
    "print(f\"       >> Early Stopping: Patience=5, Monitor='val_loss'\")\n",
    "print(f\"       >> Model Checkpoint: Save best model to '{MODEL_CHECKPOINT_PATH}'\")\n",
    "print(f\"       >> Callbacks ready for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7635689",
   "metadata": {},
   "source": [
    "## 7. Model Training\n",
    "Train the Mini-ResNet model with the configured parameters and callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b407b116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting model training...\n",
      "================================================================================\n",
      "Epoch 1/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.7866 - loss: 0.4689 - precision: 0.7719 - recall: 0.8104\n",
      "Epoch 1: val_loss improved from None to 0.30857, saving model to ./models\\meme_detector_model.h5\n",
      "\n",
      "Epoch 1: val_loss improved from None to 0.30857, saving model to ./models\\meme_detector_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1655s\u001b[0m 231ms/step - accuracy: 0.8546 - loss: 0.3539 - precision: 0.8342 - recall: 0.8834 - val_accuracy: 0.8843 - val_loss: 0.3086 - val_precision: 0.9771 - val_recall: 0.7894\n",
      "Epoch 2/15\n",
      "Epoch 2/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9056 - loss: 0.2481 - precision: 0.8834 - recall: 0.9338\n",
      "Epoch 2: val_loss improved from 0.30857 to 0.20917, saving model to ./models\\meme_detector_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.30857 to 0.20917, saving model to ./models\\meme_detector_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1248s\u001b[0m 178ms/step - accuracy: 0.9086 - loss: 0.2499 - precision: 0.8867 - recall: 0.9359 - val_accuracy: 0.9470 - val_loss: 0.2092 - val_precision: 0.9650 - val_recall: 0.9286\n",
      "Epoch 3/15\n",
      "Epoch 3/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9215 - loss: 0.2303 - precision: 0.9014 - recall: 0.9456\n",
      "Epoch 3: val_loss improved from 0.20917 to 0.20384, saving model to ./models\\meme_detector_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.20917 to 0.20384, saving model to ./models\\meme_detector_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1292s\u001b[0m 180ms/step - accuracy: 0.9199 - loss: 0.2303 - precision: 0.8999 - recall: 0.9439 - val_accuracy: 0.9273 - val_loss: 0.2038 - val_precision: 0.9701 - val_recall: 0.8827\n",
      "Epoch 4/15\n",
      "Epoch 4/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9231 - loss: 0.2165 - precision: 0.9030 - recall: 0.9472\n",
      "Epoch 4: val_loss did not improve from 0.20384\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1249s\u001b[0m 178ms/step - accuracy: 0.9245 - loss: 0.2151 - precision: 0.9052 - recall: 0.9475 - val_accuracy: 0.9337 - val_loss: 0.2187 - val_precision: 0.9706 - val_recall: 0.8954\n",
      "Epoch 5/15\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.20384\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1249s\u001b[0m 178ms/step - accuracy: 0.9245 - loss: 0.2151 - precision: 0.9052 - recall: 0.9475 - val_accuracy: 0.9337 - val_loss: 0.2187 - val_precision: 0.9706 - val_recall: 0.8954\n",
      "Epoch 5/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9233 - loss: 0.2130 - precision: 0.9061 - recall: 0.9437\n",
      "Epoch 5: val_loss improved from 0.20384 to 0.18228, saving model to ./models\\meme_detector_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.20384 to 0.18228, saving model to ./models\\meme_detector_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 180ms/step - accuracy: 0.9249 - loss: 0.2089 - precision: 0.9077 - recall: 0.9451 - val_accuracy: 0.9307 - val_loss: 0.1823 - val_precision: 0.9704 - val_recall: 0.8896\n",
      "Epoch 6/15\n",
      "Epoch 6/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9286 - loss: 0.2074 - precision: 0.9103 - recall: 0.9504\n",
      "Epoch 6: val_loss did not improve from 0.18228\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1261s\u001b[0m 180ms/step - accuracy: 0.9289 - loss: 0.2050 - precision: 0.9123 - recall: 0.9483 - val_accuracy: 0.9323 - val_loss: 0.2310 - val_precision: 0.9698 - val_recall: 0.8934\n",
      "Epoch 7/15\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.18228\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1261s\u001b[0m 180ms/step - accuracy: 0.9289 - loss: 0.2050 - precision: 0.9123 - recall: 0.9483 - val_accuracy: 0.9323 - val_loss: 0.2310 - val_precision: 0.9698 - val_recall: 0.8934\n",
      "Epoch 7/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9302 - loss: 0.2038 - precision: 0.9094 - recall: 0.9541\n",
      "Epoch 7: val_loss improved from 0.18228 to 0.15716, saving model to ./models\\meme_detector_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.18228 to 0.15716, saving model to ./models\\meme_detector_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1278s\u001b[0m 182ms/step - accuracy: 0.9289 - loss: 0.2049 - precision: 0.9094 - recall: 0.9521 - val_accuracy: 0.9457 - val_loss: 0.1572 - val_precision: 0.9566 - val_recall: 0.9344\n",
      "Epoch 8/15\n",
      "Epoch 8/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9292 - loss: 0.2000 - precision: 0.9128 - recall: 0.9483\n",
      "Epoch 8: val_loss did not improve from 0.15716\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1284s\u001b[0m 183ms/step - accuracy: 0.9312 - loss: 0.1997 - precision: 0.9149 - recall: 0.9500 - val_accuracy: 0.9180 - val_loss: 0.2225 - val_precision: 0.9732 - val_recall: 0.8616\n",
      "Epoch 9/15\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.15716\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1284s\u001b[0m 183ms/step - accuracy: 0.9312 - loss: 0.1997 - precision: 0.9149 - recall: 0.9500 - val_accuracy: 0.9180 - val_loss: 0.2225 - val_precision: 0.9732 - val_recall: 0.8616\n",
      "Epoch 9/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9353 - loss: 0.1873 - precision: 0.9182 - recall: 0.9552\n",
      "Epoch 9: val_loss did not improve from 0.15716\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1258s\u001b[0m 180ms/step - accuracy: 0.9328 - loss: 0.1888 - precision: 0.9166 - recall: 0.9515 - val_accuracy: 0.8963 - val_loss: 0.2858 - val_precision: 0.9710 - val_recall: 0.8188\n",
      "Epoch 10/15\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.15716\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1258s\u001b[0m 180ms/step - accuracy: 0.9328 - loss: 0.1888 - precision: 0.9166 - recall: 0.9515 - val_accuracy: 0.8963 - val_loss: 0.2858 - val_precision: 0.9710 - val_recall: 0.8188\n",
      "Epoch 10/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9327 - loss: 0.1919 - precision: 0.9153 - recall: 0.9525\n",
      "Epoch 10: val_loss did not improve from 0.15716\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9991s\u001b[0m 1s/step - accuracy: 0.9343 - loss: 0.1884 - precision: 0.9162 - recall: 0.9554 - val_accuracy: 0.9147 - val_loss: 0.2426 - val_precision: 0.9597 - val_recall: 0.8671\n",
      "Epoch 11/15\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.15716\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9991s\u001b[0m 1s/step - accuracy: 0.9343 - loss: 0.1884 - precision: 0.9162 - recall: 0.9554 - val_accuracy: 0.9147 - val_loss: 0.2426 - val_precision: 0.9597 - val_recall: 0.8671\n",
      "Epoch 11/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9382 - loss: 0.1820 - precision: 0.9199 - recall: 0.9594\n",
      "Epoch 11: val_loss did not improve from 0.15716\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1373s\u001b[0m 196ms/step - accuracy: 0.9364 - loss: 0.1834 - precision: 0.9207 - recall: 0.9545 - val_accuracy: 0.9127 - val_loss: 0.2918 - val_precision: 0.9743 - val_recall: 0.8495\n",
      "Epoch 12/15\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.15716\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1373s\u001b[0m 196ms/step - accuracy: 0.9364 - loss: 0.1834 - precision: 0.9207 - recall: 0.9545 - val_accuracy: 0.9127 - val_loss: 0.2918 - val_precision: 0.9743 - val_recall: 0.8495\n",
      "Epoch 12/15\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9340 - loss: 0.1853 - precision: 0.9172 - recall: 0.9535\n",
      "Epoch 12: val_loss did not improve from 0.15716\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1371s\u001b[0m 196ms/step - accuracy: 0.9356 - loss: 0.1813 - precision: 0.9189 - recall: 0.9549 - val_accuracy: 0.9307 - val_loss: 0.2196 - val_precision: 0.9684 - val_recall: 0.8915\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.15716\n",
      "\u001b[1m7000/7000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1371s\u001b[0m 196ms/step - accuracy: 0.9356 - loss: 0.1813 - precision: 0.9189 - recall: 0.9549 - val_accuracy: 0.9307 - val_loss: 0.2196 - val_precision: 0.9684 - val_recall: 0.8915\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\n",
      "================================================================================\n",
      "[INFO] Model training completed successfully\n",
      "       >> Final training accuracy: 0.9356\n",
      "       >> Final validation accuracy: 0.9307\n",
      "       >> Best model saved to: ./models\\meme_detector_model.h5\n",
      "\n",
      "================================================================================\n",
      "[INFO] Model training completed successfully\n",
      "       >> Final training accuracy: 0.9356\n",
      "       >> Final validation accuracy: 0.9307\n",
      "       >> Best model saved to: ./models\\meme_detector_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"[INFO] Starting model training...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] Model training completed successfully\")\n",
    "print(f\"       >> Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"       >> Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"       >> Best model saved to: {MODEL_CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46daa162",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n",
    "Evaluate the trained model on the test dataset and calculate performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b113b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading best model for evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       >> Model loaded from: ./models\\meme_detector_model.h5\n",
      "\n",
      "[INFO] Evaluating model on test dataset...\n",
      "================================================================================\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 69ms/step - accuracy: 0.9440 - loss: 0.1659 - precision: 0.9513 - recall: 0.9375\n",
      "\n",
      "================================================================================\n",
      "[INFO] Test Results:\n",
      "       >> Test Loss:      0.1659\n",
      "       >> Test Accuracy:  0.9440 (94.40%)\n",
      "       >> Test Precision: 0.9513\n",
      "       >> Test Recall:    0.9375\n",
      "       >> Test F1-Score:  0.9444\n",
      "================================================================================\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 69ms/step - accuracy: 0.9440 - loss: 0.1659 - precision: 0.9513 - recall: 0.9375\n",
      "\n",
      "================================================================================\n",
      "[INFO] Test Results:\n",
      "       >> Test Loss:      0.1659\n",
      "       >> Test Accuracy:  0.9440 (94.40%)\n",
      "       >> Test Precision: 0.9513\n",
      "       >> Test Recall:    0.9375\n",
      "       >> Test F1-Score:  0.9444\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load the best model for evaluation\n",
    "print(\"[INFO] Loading best model for evaluation...\")\n",
    "best_model = tf.keras.models.load_model(MODEL_CHECKPOINT_PATH)\n",
    "print(f\"       >> Model loaded from: {MODEL_CHECKPOINT_PATH}\")\n",
    "\n",
    "# Evaluate on test dataset\n",
    "print(\"\\n[INFO] Evaluating model on test dataset...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_results = best_model.evaluate(test_ds, verbose=1)\n",
    "\n",
    "# Extract metrics\n",
    "test_loss = test_results[0]\n",
    "test_accuracy = test_results[1]\n",
    "test_precision = test_results[2]\n",
    "test_recall = test_results[3]\n",
    "\n",
    "# Calculate F1-Score\n",
    "if test_precision + test_recall > 0:\n",
    "    test_f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "else:\n",
    "    test_f1_score = 0.0\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] Test Results:\")\n",
    "print(f\"       >> Test Loss:      {test_loss:.4f}\")\n",
    "print(f\"       >> Test Accuracy:  {test_accuracy:.4f} ({test_accuracy * 100:.2f}%)\")\n",
    "print(f\"       >> Test Precision: {test_precision:.4f}\")\n",
    "print(f\"       >> Test Recall:    {test_recall:.4f}\")\n",
    "print(f\"       >> Test F1-Score:  {test_f1_score:.4f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a65ff3",
   "metadata": {},
   "source": [
    "## 9. Model Saving\n",
    "The best model has already been saved during training via ModelCheckpoint callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd5a0326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model successfully saved!\n",
      "       >> Location: ./models\\meme_detector_model.h5\n",
      "       >> Size: 33.03 MB\n",
      "       >> Model ready for inference\n"
     ]
    }
   ],
   "source": [
    "# Verify model was saved\n",
    "if os.path.exists(MODEL_CHECKPOINT_PATH):\n",
    "    model_size = os.path.getsize(MODEL_CHECKPOINT_PATH) / (1024 * 1024)  # Size in MB\n",
    "    print(f\"[INFO] Model successfully saved!\")\n",
    "    print(f\"       >> Location: {MODEL_CHECKPOINT_PATH}\")\n",
    "    print(f\"       >> Size: {model_size:.2f} MB\")\n",
    "    print(f\"       >> Model ready for inference\")\n",
    "else:\n",
    "    print(f\"[WARNING] Model file not found at: {MODEL_CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd7a00d",
   "metadata": {},
   "source": [
    "## 10. Prediction Function\n",
    "Define a prediction function to classify individual images as Meme or Non-Meme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be53b074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Prediction function defined successfully\n",
      "       >> Function: predict_meme(img_path)\n",
      "       >> Usage: predict_meme('path/to/image.jpg')\n"
     ]
    }
   ],
   "source": [
    "# Image prediction function\n",
    "def predict_meme(img_path, model_path='./models/meme_detector_model.h5', img_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Predict whether an image is a Meme or Non-Meme using the trained Mini-ResNet model.\n",
    "    \n",
    "    Args:\n",
    "        img_path (str): Path to the image file\n",
    "        model_path (str): Path to the saved model file\n",
    "        img_size (tuple): Size to resize the image to (height, width)\n",
    "    \n",
    "    Returns:\n",
    "        None: Prints the prediction result with confidence\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the trained model\n",
    "        loaded_model = tf.keras.models.load_model(model_path)\n",
    "        \n",
    "        # Load and preprocess the image\n",
    "        img = image.load_img(img_path, target_size=img_size)\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = img_array / 255.0  # Normalize to [0, 1]\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = loaded_model.predict(img_array, verbose=0)[0, 0]\n",
    "        \n",
    "        # Interpret prediction\n",
    "        # prediction < 0.5 means Meme (class 0)\n",
    "        # prediction >= 0.5 means Non-Meme (class 1)\n",
    "        if prediction >= 0.5:\n",
    "            label = \"Non-Meme\"\n",
    "            confidence = prediction\n",
    "        else:\n",
    "            label = \"Meme\"\n",
    "            confidence = 1 - prediction\n",
    "        \n",
    "        print(f\"[PREDICTION] {img_path}\")\n",
    "        print(f\"             >> Result: {label}\")\n",
    "        print(f\"             >> Confidence: {confidence:.2%}\")\n",
    "        print(f\"             >> Raw score: {prediction:.4f}\")\n",
    "        print()\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"[ERROR] Image file not found: {img_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Prediction failed for {img_path}: {str(e)}\")\n",
    "\n",
    "print(\"[INFO] Prediction function defined successfully\")\n",
    "print(\"       >> Function: predict_meme(img_path)\")\n",
    "print(\"       >> Usage: predict_meme('path/to/image.jpg')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288cd149",
   "metadata": {},
   "source": [
    "## 11. Test Predictions\n",
    "Test the prediction function on sample images (modify paths as needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5546db27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running sample predictions...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREDICTION] prediction_test/test_001.png\n",
      "             >> Result: Non-Meme\n",
      "             >> Confidence: 89.39%\n",
      "             >> Raw score: 0.8939\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREDICTION] prediction_test/test_002.png\n",
      "             >> Result: Non-Meme\n",
      "             >> Confidence: 63.51%\n",
      "             >> Raw score: 0.6351\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREDICTION] prediction_test/test_003.png\n",
      "             >> Result: Non-Meme\n",
      "             >> Confidence: 98.09%\n",
      "             >> Raw score: 0.9809\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREDICTION] prediction_test/test_004.jpg\n",
      "             >> Result: Meme\n",
      "             >> Confidence: 99.98%\n",
      "             >> Raw score: 0.0002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREDICTION] prediction_test/test_005.jpg\n",
      "             >> Result: Meme\n",
      "             >> Confidence: 100.00%\n",
      "             >> Raw score: 0.0000\n",
      "\n",
      "[INFO] To test predictions, uncomment and modify the paths above\n",
      "       >> Example: predict_meme('path/to/your/image.jpg')\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example predictions (uncomment and modify paths to test with actual images)\n",
    "print(\"[INFO] Running sample predictions...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Example usage:\n",
    "# predict_meme(\"meme_vs_not_meme_dataset/meme/sample_meme.jpg\")\n",
    "# predict_meme(\"meme_vs_not_meme_dataset/not_meme/sample_not_meme.jpg\")\n",
    "\n",
    "predict_meme(\"prediction_test/test_001.png\")\n",
    "predict_meme(\"prediction_test/test_002.png\")\n",
    "predict_meme(\"prediction_test/test_003.png\")\n",
    "predict_meme(\"prediction_test/test_004.jpg\")\n",
    "predict_meme(\"prediction_test/test_005.jpg\")\n",
    "\n",
    "print(\"[INFO] To test predictions, uncomment and modify the paths above\")\n",
    "print(\"       >> Example: predict_meme('path/to/your/image.jpg')\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233f42b",
   "metadata": {},
   "source": [
    "## 12. Cleanup - Remove Temporary Files\n",
    "Clean up temporary balanced dataset directory to free up disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c014c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Cleaning up temporary files...\n",
      "       >> Temporary dataset directory removed: ./temp_balanced_dataset\n",
      "       >> Disk space freed successfully\n",
      "[INFO] Cleanup completed!\n",
      "       >> Temporary dataset directory removed: ./temp_balanced_dataset\n",
      "       >> Disk space freed successfully\n",
      "[INFO] Cleanup completed!\n"
     ]
    }
   ],
   "source": [
    "# Clean up temporary balanced dataset directory\n",
    "print(\"[INFO] Cleaning up temporary files...\")\n",
    "\n",
    "if os.path.exists(TEMP_DATASET_DIR):\n",
    "    shutil.rmtree(TEMP_DATASET_DIR)\n",
    "    print(f\"       >> Temporary dataset directory removed: {TEMP_DATASET_DIR}\")\n",
    "    print(f\"       >> Disk space freed successfully\")\n",
    "else:\n",
    "    print(f\"       >> No temporary files to clean up\")\n",
    "\n",
    "print(\"[INFO] Cleanup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc4ef73",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook successfully implemented a **Meme vs. Non-Meme Binary Classification Model** using a Mini-ResNet architecture with the following key features:\n",
    "\n",
    "### Model Highlights:\n",
    "✅ **Architecture**: Mini-ResNet with 6 residual blocks and skip connections  \n",
    "✅ **Input Size**: 224×224 RGB images  \n",
    "✅ **Output**: Binary classification (0 = Non-Meme, 1 = Meme)  \n",
    "✅ **Optimizer**: Adam with learning rate 0.0001  \n",
    "✅ **Batch Size**: 2  \n",
    "✅ **Epochs**: 15 with Early Stopping  \n",
    "\n",
    "### Advanced Dataset Handling:\n",
    "✅ **Nested Folder Support**: Automatically scans and collects images from nested subfolders  \n",
    "✅ **Image Validation**: Validates each image file to ensure it's readable by TensorFlow  \n",
    "✅ **Auto-Filtering**: Automatically filters out corrupted or invalid image files  \n",
    "✅ **Dataset Balancing**: Ensures equal number of images per class to prevent bias  \n",
    "✅ **Smart Sampling**: Randomly selects images from larger class to match smaller class  \n",
    "✅ **Multiple Format Support**: Handles .jpg, .jpeg, .png, .bmp, .gif formats  \n",
    "✅ **Configurable Max Limit**: Set `MAX_IMAGES_PER_CLASS` to limit images per class (with smart fallback)  \n",
    "\n",
    "### Data Processing:\n",
    "✅ **Dataset Split**: 70% Train / 15% Validation / 15% Test  \n",
    "✅ **Augmentation**: Rotation (±15°), Flip, Contrast, Zoom, Translation  \n",
    "✅ **Normalization**: Pixel values scaled to [0, 1]  \n",
    "✅ **Balanced Training**: Equal representation prevents model bias  \n",
    "\n",
    "### Training Features:\n",
    "✅ **Early Stopping**: Prevents overfitting  \n",
    "✅ **Model Checkpoint**: Saves best model automatically  \n",
    "✅ **Callbacks**: Optimized training process  \n",
    "✅ **Error Prevention**: Pre-validation ensures no corrupted images cause training failures  \n",
    "\n",
    "### Evaluation Metrics:\n",
    "✅ **Loss**: Binary Crossentropy  \n",
    "✅ **Metrics**: Accuracy, Precision, Recall, F1-Score  \n",
    "\n",
    "### Model Output:\n",
    "✅ **Saved Model**: `models/meme_detector_model.h5`  \n",
    "✅ **Prediction Function**: `predict_meme(img_path)`  \n",
    "✅ **Automatic Cleanup**: Removes temporary files after training  \n",
    "\n",
    "---\n",
    "\n",
    "### Image Validation & Error Prevention:\n",
    "\n",
    "The notebook automatically validates all images before training to prevent errors:\n",
    "\n",
    "**Validation Process:**\n",
    "1. Scans all subfolders for image files\n",
    "2. Attempts to load each image with TensorFlow\n",
    "3. Filters out corrupted, unreadable, or invalid files\n",
    "4. Reports the number of invalid files found\n",
    "5. Proceeds with only valid images\n",
    "\n",
    "**Benefits:**\n",
    "- ✅ Prevents `InvalidArgumentError` during training\n",
    "- ✅ Ensures all images are TensorFlow-compatible\n",
    "- ✅ No manual cleanup required\n",
    "- ✅ Clear reporting of filtered files\n",
    "\n",
    "**Example Output:**\n",
    "```\n",
    ">> Scanning directory: meme\n",
    ">> Found 10,500 potential image files\n",
    ">> Validating images (this may take a moment)...\n",
    ">> Filtered out 23 invalid/corrupted images\n",
    ">> Valid images: 10,477\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Configurable Maximum Images Per Class:\n",
    "\n",
    "You can limit the number of images used per class by setting `MAX_IMAGES_PER_CLASS`:\n",
    "\n",
    "**Example 1: No Limit (Default)**\n",
    "```python\n",
    "MAX_IMAGES_PER_CLASS = None\n",
    "```\n",
    "- Uses all available valid images after balancing\n",
    "\n",
    "**Example 2: Set Limit to 10,000**\n",
    "```python\n",
    "MAX_IMAGES_PER_CLASS = 10000\n",
    "```\n",
    "- If meme has 15,000 images → uses 10,000 (randomly selected)\n",
    "- If not_meme has 8,000 images → uses 8,000 (below limit, uses all)\n",
    "- Final result: Both classes use 8,000 images (balanced to minimum)\n",
    "\n",
    "**Example 3: Set Limit to 5,000**\n",
    "```python\n",
    "MAX_IMAGES_PER_CLASS = 5000\n",
    "```\n",
    "- If meme has 7,000 images → limits to 5,000\n",
    "- If not_meme has 6,000 images → limits to 5,000\n",
    "- Final result: Both classes use 5,000 images (balanced)\n",
    "\n",
    "**How It Works:**\n",
    "1. Validates all images first (filters out corrupted files)\n",
    "2. Applies `MAX_IMAGES_PER_CLASS` limit to each folder independently\n",
    "3. If a folder has fewer valid images than the limit, uses actual count\n",
    "4. Then balances both classes to the minimum count\n",
    "5. Ensures randomization for fair sampling (seed=42 for reproducibility)\n",
    "\n",
    "---\n",
    "\n",
    "### How It Handles Nested Folders:\n",
    "\n",
    "If your dataset structure looks like this:\n",
    "```\n",
    "meme_vs_not_meme_dataset/\n",
    "    meme/\n",
    "        subfolder1/\n",
    "            image1.jpg\n",
    "            image2.png\n",
    "        subfolder2/\n",
    "            image3.jpg\n",
    "    not_meme/\n",
    "        another_folder/\n",
    "            image4.jpg\n",
    "        image5.png\n",
    "```\n",
    "\n",
    "The notebook will:\n",
    "1. **Recursively scan** all subfolders in `meme/` and `not_meme/`\n",
    "2. **Validate each image** using TensorFlow (filters corrupted files)\n",
    "3. **Collect all valid images** regardless of nesting depth\n",
    "4. **Apply max limit** if configured (per class)\n",
    "5. **Balance the dataset** automatically (equal images per class)\n",
    "6. **Create a temporary flat structure** for training\n",
    "7. **Clean up** temporary files after training\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: To train the model, ensure the `meme_vs_not_meme_dataset/` directory contains images in `meme/` and `not_meme/` folders (nested subfolders are supported). Invalid or corrupted images will be automatically filtered out."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
